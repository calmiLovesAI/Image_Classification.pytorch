Optimizer:
  chosen_name: "Adam"
  Adam:
    name: "Adam"
    lr: 1.0e-4
    betas:
      - 0.9
      - 0.999
    eps:
      1.0e-8
    weight_decay: 0
  SGD:
    name: "SGD"
    lr: 1.0e-3
    momentum: 0
    weight_decay: 0
Scheduler:
  chosen_name: ""   # ""表示不使用学习率下降策略
  MultiStepLR:
    name: "MultiStepLR"
    milestones: [30, 40]
    gamma: 0.1